\documentclass{article}

\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[english]{babel}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}

\begin{document}

\title{Information, Codes and Ciphers}
\author{Hao Ren}
\date{\today}
\maketitle

\setcounter{section}{2}

\newpage

\section{Compression Coding}

\subsection{Variable Length Encoding}

\subsubsection{Definition}

\begin{align*}
	\text{a source } S \qquad &\text{ with } q \text{ source symbols} \qquad & s_{1},s_{2},\cdots,s_{q},\\
	&\text{ with probabilities} \qquad &  p_{1},p_{2},\cdots,p_{q},\\
	\text{encoded by a code } C \qquad &\text{ with } q \text{ codewords} \qquad & c_{1},c_{2},\cdots,c_{q},\\
	&\text{ of lengths} \qquad & l_{1},l_{2},\cdots,l_{q}.
\end{align*}

\begin{itemize}
	\item with a radix $r$ codewords,
	\item variable length codes,
	\item not channel noise for source coding.
\end{itemize}

\subsubsection{UD and I-code}

A code $C$ is

\begin{description}
	\item[UD] uniquely decodable codes if it can always be decoded unambiguously,
	\item[I-code] instantaneous if no codeword is the prefix of others.
\end{description}

\subsubsection{Comma Codes}

The standard comma code of length $n$ is

\begin{itemize}
	\item a code which every codeword has length $\leq n$,
	\item a code which every codeword contains at most one $0$,
	\item and if a codeword contains $0$ then $0$ must be the final symbol in the codeword.
\end{itemize}

\subsubsection{Decision Trees}

\subsubsection{The Kraft-McMillan Theorem}

\begin{theorem}[The Kraft-McMillan Theorem]
	\mbox{}\\
	A UD-code of radix $r$ with $q$ codewords $c_{1}, c_{2},\cdots,c_{q}$ of lengths $l_{1} \leq l_{2} \leq \cdots \leq l_{q}$ exists \\
	if and only if \qquad an I-code with the same parameters exists \\
	if and only if
	\[K=\sum_{i=1}^{q}\frac{1}{r^{l_{i}}}\leq1. \]
\end{theorem}

\subsubsection{Length and Variance}

The expected or \textbf{average length} of codewords is given by
	\[L=\sum_{i=1}^{q}p_{i}l_{i}\]
	and the \textbf{variance} is given by
	\[V=\sum_{i=1}^{q}p_{i}l_{i}^{2}-L^{2}.\]

Our aim is to minimise $L$ for a given source $S$ and, if more than one code $C$ gives this value, to minimise $V$.

\begin{theorem}[Minimal UD-codes]
	\mbox{}\\
	Let $C$ be a UD-code with minimal expected length $L$ for the given source $S$. Then, after permuting codewords of equally likely symbols if necessary,
	\begin{itemize}
		\item $l_{1} \leq l_{2} \leq \cdots \leq l_{q}$ and
		\item $l_{q-1}=l_{1}$.
	\end{itemize}
	Furthermore, if C is instantaneous, then
	\begin{itemize}
		\item $c_{q-1}$ and $c_{q}$ differ only in their last place.
	\end{itemize}
	If $C$ is binary, then
	\begin{itemize}
		\item $K=\sum_{i=1}^{q}2^{-l_{i}}=1.$
	\end{itemize}
\end{theorem}

\subsection{Huffman's Algorithm}

\subsubsection{Huffman Coding}

To compute Huffman prefix-free code:

\begin{itemize}
	\item Count character frequencies ps for each symbol $s$ in file.
	\item Start with a forest of trees, each consisting of a single vertex corresponding to each symbol $s$ with weight $p_{s}$.
	\item Repeat:
		\begin{itemize}
			\item select two trees with min weight $p_{1}$ and $p_{2}$
			\item merge into single tree with weight $p_{1}+p_{2}$
		\end{itemize}
\end{itemize}

\paragraph{Applications} JPEG, MP3, MPEG, PKZIP.

\begin{theorem}[Huffman Code Theorem]
	\mbox{}\\
	For the given source $S$, the Huffman algorithm produces a minimum average length UD-code which is an instantaneous code.
\end{theorem}

\begin{proposition}[Knuth]
	\mbox{}\\
	For a Huffman code created by the given algorithm, the average code word length is sum of all the probabilities at child nodes.
\end{proposition}

\subsubsection{Properties of Huffman Codes}

\begin{enumerate}
	\item The place high strategy always produces a minimum variance Huffman code .
	\item If there are $2^{n}$ equally likely source symbols then the Huffman code is a block code of length $n$.
	\item If for all $j$, $3p_{j} \geq 2 \sum_{k=j+1}^{q}p_{k}$ then the Huffman code is a comma code.
	\item Small changes in the pi can change the Huffman code substantially, but have little effect on the average length $L$. This effect is smaller with smaller variance.
\end{enumerate}

\section*{Resources}

\end{document}
